{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22475529",
   "metadata": {},
   "source": [
    "# LELEC2910 - Project part I\n",
    "\n",
    "This notebook serves as a tutorial for the **first part** of the project. It complements the detailed guidelines for the project that are available on Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "from scipy import fft\n",
    "from skyfield.api import load, wgs84, EarthSatellite\n",
    "\n",
    "import utils #utils.py, gathers useful functions for loading and plotting Alphasat measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c75030",
   "metadata": {},
   "source": [
    "## 1) Load Alphasat measurements \n",
    "The cell below loads Alphasat measurements for a chosen month (either 'september2019', 'december2020', 'march2021', 'june2021'). Four months of data are provided, one per season. They do not come from the same year as the Alphasat receiver sometimes suffer from failure events, preventing the use of its data. Hence, the months have been chosen in order to give you data of good quality, i.e., without too many missing days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b1228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Alphasat measurements\n",
    "month_name: str = 'june2021' #'september2019'#'march2021'#'december2020'#'june2021'\n",
    "df_ch1, df_ch2, df_ch3, df_ch4 = utils.load_data('data', month_name)\n",
    "\n",
    "# Print the dataframe associated to channel 2, to show you its content\n",
    "# print(df_ch2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af940771",
   "metadata": {},
   "source": [
    "## 2) Rain and failure events\n",
    "The identification of rain events has already been conducted, using visual inspection. Start and end dates of rain events are gathered in the events.csv file, loaded in the cell below. Then, a flag is added to the measurement dataframes, using the following convention: 0 for data under clear sky, 1 for data during a rain event, 2 for a failure of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54b6645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load event file\n",
    "event_file = 'events.csv'\n",
    "df_event = pd.read_csv(event_file)\n",
    "\n",
    "idx: int\n",
    "last_idx: int = df_event.shape[0]-1\n",
    "n_error_days: int = 0\n",
    "event: pd.core.series.Series\n",
    "_1sec: timedelta = timedelta(seconds=1)\n",
    "\n",
    "for idx, event in df_event.iterrows():\n",
    "    event.loc['TIME START'] = pd.to_datetime(event.loc['DATE'], format='%Y-%m-%d') + pd.to_timedelta(event.loc['TIME START'])\n",
    "    event.loc['TIME STOP'] = pd.to_datetime(event.loc['DATE'], format='%Y-%m-%d') + pd.to_timedelta(event.loc['TIME STOP'])\n",
    "    event.loc['DURATION'] = pd.to_timedelta(event.loc['DURATION'])\n",
    "\n",
    "df_event.drop(labels='DATE', axis='columns', inplace=True)\n",
    "\n",
    "for idx, event in df_event.iterrows():\n",
    "    if idx == last_idx: continue\n",
    "    while (df_event.loc[idx+n_error_days, 'TIME STOP'] == df_event.loc[idx+n_error_days+1, 'TIME START'] - _1sec and\n",
    "           df_event.loc[idx+n_error_days, 'EVENT'] == df_event.loc[idx+n_error_days+1, 'EVENT'] and\n",
    "           idx+n_error_days < last_idx):\n",
    "        n_error_days += 1\n",
    "        if idx+n_error_days == last_idx:\n",
    "            break\n",
    "    sum_duration: timedelta = np.sum(df_event.loc[idx:idx+n_error_days, 'DURATION'])\n",
    "    for i in range(n_error_days):\n",
    "        df_event.loc[idx+i+1, 'TIME START'] = event.loc['TIME START']\n",
    "        df_event.loc[idx+i, 'TIME STOP'] = df_event.loc[idx+n_error_days, 'TIME STOP']\n",
    "        df_event.loc[idx+i, 'DURATION'] = sum_duration + n_error_days*_1sec\n",
    "        df_event.loc[idx+i+1, 'DURATION'] = sum_duration + n_error_days*_1sec\n",
    "    n_error_days = 0\n",
    "\n",
    "df_event.drop_duplicates(inplace=True, ignore_index=True)\n",
    "\n",
    "# Print the loaded event file to show you its content\n",
    "# print(df_event[:61]) #september2019\n",
    "# print(df_event[61:84]) #december2020\n",
    "# print(df_event[84:104]) #march2021\n",
    "# print(df_event[104:]) #june2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ed0094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition of a flag, based on the recorded events\n",
    "df_ch1, df_ch2, df_ch3, df_ch4 = utils.add_flags(df_event, df_ch1, df_ch2, df_ch3, df_ch4)\n",
    "\n",
    "# Print of the second channel dataframe after the flag addition\n",
    "# print(df_ch2['flag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b54f3c",
   "metadata": {},
   "source": [
    "### Plot of loaded data\n",
    "The cell below plots the loaded data for each day in the selected date range. It uses the plot_one_day_4ch() function defined in utils.py. The last argument of the function is a boolean to set to 'true' to save the figure for each day (in the /figure folder). You are encouraged to run the plots for all dates in the chosen month, and then skim through the saved figures. On each figure, rain events are depicted in red, while failure events are in grey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6047dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the start and end dates according to the month\n",
    "all_dates = pd.date_range(start='2021-03-30', end='2021-03-30')\n",
    "\n",
    "for date in all_dates:\n",
    "    utils.plot_one_day_4ch(date, df_ch1, df_ch2, df_ch3, df_ch4, bool_save=True, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92b6318",
   "metadata": {},
   "source": [
    "## 3) Excess attenuation and statistics\n",
    "It is now your turn to process the data and extract the excess attenuation for each month, at each frequency. Start with the excess attenuation time series, and then compute its statistics (CCDF). Remember to first define a template to determine the 0dB level.\n",
    "\n",
    "**Make sure to remove failure events when you compute the statistics (especially for June 2021).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98991c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add S(w), S_filt(w), freqs and signal_filt for each no rain no failure window\n",
    "\n",
    "freq_filt_param: int = 10_000\n",
    "\n",
    "for ch in (df_ch1, df_ch2, df_ch3, df_ch4):\n",
    "    ch['signal_filt'] = np.full_like(ch['signal'], np.nan, dtype=float)\n",
    "    ch['S(w)'] = np.zeros_like(ch['signal'], dtype=complex)\n",
    "    ch['S_filt(w)'] = np.zeros_like(ch['signal'], dtype=complex)\n",
    "    ch['freqs'] = np.zeros_like(ch['signal'], dtype=float)\n",
    "    \n",
    "    # Iterate over all events with flag=0, filter the signal with frequency spectrum windowing\n",
    "    for idx in range(len(df_event)+1):\n",
    "        idx_slice: pd.core.series.Series = ch['ind_event'] == idx\n",
    "        x: np.ndarray[float] = ch.loc[idx_slice, 'signal'].array\n",
    "        if len(x) == 0: continue\n",
    "        extend_len: int = min(len(x), freq_filt_param)\n",
    "        longer_x = np.concatenate((x[::-1][-extend_len:], x, x[::-1][:extend_len]))\n",
    "        l: int = len(longer_x)\n",
    "        X: np.ndarray[float] = fft.fft(longer_x, norm='forward')\n",
    "        half_win_width: int = l//freq_filt_param+1\n",
    "        window: np.ndarray[float] = np.zeros(l, dtype=float)\n",
    "        window[:half_win_width] = 1.0\n",
    "        window[len(window)-(half_win_width-1):] = 1.0\n",
    "        X_filt: np.ndarray[float] = X*window\n",
    "        ch.loc[idx_slice, 'signal_filt'] = np.real(fft.ifft(X_filt, norm='forward'))[extend_len:-extend_len]\n",
    "\n",
    "    # Interpolate over invalid sequences\n",
    "    \n",
    "    ch.loc[:, 'signal_filt'] = ch.loc[:, 'signal_filt'].interpolate(method='linear', limit_direction='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500628f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot of the signal and filtered signal + interpolation during rain events \n",
    "all_dates = pd.date_range(start='2021-03-28', end='2021-03-28')\n",
    "\n",
    "for date in all_dates:\n",
    "    utils.plot_one_day_4ch(date, df_ch1, df_ch2, df_ch3, df_ch4, signal_filt=True, bool_save=True, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a477889",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in (df_ch1, df_ch2, df_ch3, df_ch4):\n",
    "    ch.loc[:, 'excess_attenuation'] = ch.loc[:, 'signal'] - ch.loc[:, 'signal_filt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4218ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find maximum attenuation per month during rain event\n",
    "for ch in (df_ch1, df_ch2, df_ch3, df_ch4):\n",
    "    max_att = np.max(np.abs(ch.where(ch['flag'] == 1)['excess_attenuation']))\n",
    "    print(max_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752a14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot of the signal excess attenuation\n",
    "\n",
    "all_dates = pd.date_range(start='2021-06-01', end='2021-06-30')\n",
    "\n",
    "for date in all_dates:\n",
    "    utils.plot_one_day_4ch(date, df_ch1, df_ch2, df_ch3, df_ch4, excess_attenuation=True, bool_save=True, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780a83f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "206b8411",
   "metadata": {},
   "source": [
    "## 4) Comparison with RAPIDS outputs\n",
    "The cell below loads RAPIDS simulation outputs at LLN for the 19.7GHz-frequency, and is given as an example. Only the total attenuation and the rain attenuation are loaded. Per frequency, two files are needed (one file is for the elevation angles $\\theta = 5°,10°,...,50°$ and the other is for $\\theta=55°,...,90°$). Plots are given as examples, and should compare with the graphs generated automatically by the RAPIDS software (available in the output files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b5b945",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Total attenuation at 19.7 GHz\n",
    "field_names = [\"SITE\",\"SATELLITE\",\"FREQUENCY\",\"ELEVATION\",\"EP\",\"PROBABILITY\",\"ATTENUATION\"] #for total attenuation\n",
    "\n",
    "file1 = pd.read_csv(\"rapids/lln_19GHz_1/output/ascii/attenuation_total.csv\",skiprows=7,names=field_names)\n",
    "file2 = pd.read_csv(\"rapids/lln_19GHz_2/output/ascii/attenuation_total.csv\",skiprows=7,names=field_names)\n",
    "rapids_total_attenuation = pd.concat((file1,file2))\n",
    "\n",
    "print(rapids_total_attenuation)\n",
    "utils.plot_RAPIDS_outputs(rapids_total_attenuation,\"Total attenuation for LLN at 19.7 GHz\")\n",
    "\n",
    "\n",
    "### Rain attenuation at 19.7 GHz\n",
    "field_names = [\"SITE\",\"SATELLITE\",\"FREQUENCY\",\"ELEVATION\",\"ELEVATION_PROBABILITY\",\"PROBABILITY\",\"HR\",\"R001\",\"K\",\"ALPHA\",\"ATTENUATION\"] #for rain\n",
    "\n",
    "file1 = pd.read_csv(\"rapids/lln_19GHz_1/output/ascii/attenuation_rain.csv\",skiprows=7,names=field_names)\n",
    "file2 = pd.read_csv(\"rapids/lln_19GHz_2/output/ascii/attenuation_rain.csv\",skiprows=7,names=field_names)\n",
    "rapids_rain_attenuation = pd.concat((file1,file2))\n",
    "\n",
    "print(rapids_rain_attenuation)\n",
    "utils.plot_RAPIDS_outputs(rapids_rain_attenuation,\"Rain attenuation for LLN at 19.7 GHz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f63bbf0",
   "metadata": {},
   "source": [
    "At this point, you should be able to compare your measured statistics with the ones from RAPIDS, knowing the elevation angle of the Alphasat satellite as seen from Louvain-la-Neuve (see slides of the project introduction session)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486c96ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
